{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement:\n",
    "\n",
    "### The Credit Card Fraud Detection Problem includes modeling past credit card transactions with the knowledge of the ones that turned out to be fraud. This model is then used to identify whether a new transaction is fraudulent or not. Our aim here is to detect 100% of the fraudulent transactions while minimizing the incorrect fraud classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "### The data set is highly skewed, consisting of 492 frauds in a total of 284,807 observations. \n",
    "### This resulted in only 0.172% fraud cases. This skewed set is justified by the low number of fraudulent transactions.\n",
    "### The dataset consists of numerical values from the 28 ‘Principal Component Analysis (PCA)’ transformed features, namely V1 to V28. \n",
    "### Furthermore, there is no metadata about the original features provided, so pre-analysis or feature study could not be done.\n",
    "### The ‘Time’ and ‘Amount’ features are not transformed data.\n",
    "###  There is no missing value in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferences drawn:\n",
    "\n",
    "### Owing to such imbalance in data, an algorithm that does not do any feature analysis and predicts all the transactions as non-frauds will also achieve an accuracy of 99.828%. Therefore, accuracy is not a correct measure of efficiency in our case. We need some other standard of correctness while classifying transactions as fraud or non-fraud.\n",
    "### The ‘Time’ feature does not indicate the actual time of the transaction and is more of a list of the data in chronological order. So we assume that the ‘Time’ feature has little or no significance in classifying a fraud transaction. Therefore, we eliminate this column from further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incorrect Measures of Efficiency of a Data Model:\n",
    "\n",
    "### Let’s look at the various measures of efficiency that fail at analyzing the correctness of the underlying data model.\n",
    "\n",
    "### Total/Net Accuracy: One approach to gauge the compute model’s correctness is to use Accuracy as the deciding parameter. But, as stated earlier, in a highly skewed data set like this, we know that even if we predict all values as non-fraudulent, we’ll have only 492 wrong predictions out of 284,807 in total. So, the accuracy is excellent, but it still doesn’t solve our problem as we want to identify as many fraud cases as possible. So, we can’t use accuracy as a deciding factor here.\n",
    "\n",
    "### Confusion Matrix: Merely tabulating the confusion matrix will not provide a clear understanding of the performance of the data. This is because the total number of fraud cases is much less, and variation in the confusion matrix will be so small that it will be equivalent to a justified error in a balanced dataset (probably even less!). So, this measure is also ruled out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import precision_score, f1_score, recall_score, roc_auc_score, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline as imbalaced_make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"D:\\Downloads\\Videos\\Krish\\Datasets\\Credit Card\\creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Value Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fraud Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284315"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_cases = data['Class'].value_counts()[0]\n",
    "fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non Fraud Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_fraud_cases =  data['Class'].value_counts()[1]\n",
    "non_fraud_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## % of both classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of No_Fraud 99.83\n",
      "% of No_Fraud 0.17\n"
     ]
    }
   ],
   "source": [
    "print('% of No_Fraud', round(data['Class'].value_counts()[0] / len(data) * 100,2))\n",
    "print('% of No_Fraud', round(data['Class'].value_counts()[1] / len(data) * 100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Countplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Class Distribution')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot('Class', data = data)\n",
    "plt.title('Class Distribution', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_fraud = 0, fraud = 1\n",
    "# imbalanced dataset - overfitting \n",
    "# we need model to consider both cases equally and model should be able to detect signs of fraud "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "std_scalar = StandardScaler()\n",
    "rob_scalar = RobustScaler() # less prone to outliers\n",
    "\n",
    "data['scaled_amount'] = rob_scalar.fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "data['scaled_time'] = rob_scalar.fit_transform(data['Time'].values.reshape(-1,1))\n",
    "\n",
    "data.drop(['Amount', 'Time'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new variable for scaled amount and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.783274</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.269825</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.983721</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.418291</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.670579</td>\n",
       "      <td>-0.994960</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
       "0       1.783274    -0.994983 -1.359807 -0.072781  2.536347  1.378155   \n",
       "1      -0.269825    -0.994983  1.191857  0.266151  0.166480  0.448154   \n",
       "2       4.983721    -0.994972 -1.358354 -1.340163  1.773209  0.379780   \n",
       "3       1.418291    -0.994972 -0.966272 -0.185226  1.792993 -0.863291   \n",
       "4       0.670579    -0.994960 -1.158233  0.877737  1.548718  0.403034   \n",
       "\n",
       "         V5        V6        V7        V8  ...       V20       V21       V22  \\\n",
       "0 -0.338321  0.462388  0.239599  0.098698  ...  0.251412 -0.018307  0.277838   \n",
       "1  0.060018 -0.082361 -0.078803  0.085102  ... -0.069083 -0.225775 -0.638672   \n",
       "2 -0.503198  1.800499  0.791461  0.247676  ...  0.524980  0.247998  0.771679   \n",
       "3 -0.010309  1.247203  0.237609  0.377436  ... -0.208038 -0.108300  0.005274   \n",
       "4 -0.407193  0.095921  0.592941 -0.270533  ...  0.408542 -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_amount = data['scaled_amount']\n",
    "scaled_time = data['scaled_time']\n",
    "\n",
    "data.drop(['scaled_amount', 'scaled_time'], axis = 1, inplace = True)\n",
    "\n",
    "data.insert(0, 'scaled_amount', scaled_amount)  # Eliminated with scaled amount\n",
    "data.insert(1, 'scaled_time', scaled_time)      # Eliminated with scaled time\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>0.041920</td>\n",
       "      <td>-0.988710</td>\n",
       "      <td>-1.393265</td>\n",
       "      <td>-1.095569</td>\n",
       "      <td>2.607795</td>\n",
       "      <td>-2.529060</td>\n",
       "      <td>-0.135265</td>\n",
       "      <td>-0.373239</td>\n",
       "      <td>0.221446</td>\n",
       "      <td>-0.962847</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229820</td>\n",
       "      <td>-0.281365</td>\n",
       "      <td>0.563218</td>\n",
       "      <td>-0.129765</td>\n",
       "      <td>0.089264</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>-0.288551</td>\n",
       "      <td>-0.863521</td>\n",
       "      <td>-0.519168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254395</th>\n",
       "      <td>-0.201355</td>\n",
       "      <td>0.846086</td>\n",
       "      <td>0.202402</td>\n",
       "      <td>1.176270</td>\n",
       "      <td>0.346379</td>\n",
       "      <td>2.882138</td>\n",
       "      <td>1.407133</td>\n",
       "      <td>-0.504355</td>\n",
       "      <td>1.438537</td>\n",
       "      <td>-0.395603</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206239</td>\n",
       "      <td>0.242560</td>\n",
       "      <td>0.841230</td>\n",
       "      <td>-0.370157</td>\n",
       "      <td>-0.026012</td>\n",
       "      <td>0.491954</td>\n",
       "      <td>0.234576</td>\n",
       "      <td>-0.279788</td>\n",
       "      <td>-0.331933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218054</th>\n",
       "      <td>0.111786</td>\n",
       "      <td>0.663307</td>\n",
       "      <td>-2.034328</td>\n",
       "      <td>-1.285472</td>\n",
       "      <td>1.857375</td>\n",
       "      <td>0.800984</td>\n",
       "      <td>3.091875</td>\n",
       "      <td>1.584380</td>\n",
       "      <td>-0.289646</td>\n",
       "      <td>0.107165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151415</td>\n",
       "      <td>-0.530614</td>\n",
       "      <td>-0.810371</td>\n",
       "      <td>-0.377722</td>\n",
       "      <td>-1.004536</td>\n",
       "      <td>0.017659</td>\n",
       "      <td>-0.776990</td>\n",
       "      <td>-0.566835</td>\n",
       "      <td>-0.318421</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10801</th>\n",
       "      <td>-0.293440</td>\n",
       "      <td>-0.778827</td>\n",
       "      <td>-14.474437</td>\n",
       "      <td>6.503185</td>\n",
       "      <td>-17.712632</td>\n",
       "      <td>11.270352</td>\n",
       "      <td>-4.150142</td>\n",
       "      <td>-3.372098</td>\n",
       "      <td>-16.535807</td>\n",
       "      <td>-1.443947</td>\n",
       "      <td>...</td>\n",
       "      <td>1.101250</td>\n",
       "      <td>-2.475962</td>\n",
       "      <td>0.342391</td>\n",
       "      <td>-3.564508</td>\n",
       "      <td>-0.818140</td>\n",
       "      <td>0.153408</td>\n",
       "      <td>0.755079</td>\n",
       "      <td>2.706566</td>\n",
       "      <td>-0.992916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44270</th>\n",
       "      <td>-0.293440</td>\n",
       "      <td>-0.503084</td>\n",
       "      <td>-20.906908</td>\n",
       "      <td>9.843153</td>\n",
       "      <td>-19.947726</td>\n",
       "      <td>6.155789</td>\n",
       "      <td>-15.142013</td>\n",
       "      <td>-2.239566</td>\n",
       "      <td>-21.234463</td>\n",
       "      <td>1.151795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396655</td>\n",
       "      <td>-1.977196</td>\n",
       "      <td>0.652932</td>\n",
       "      <td>-0.519777</td>\n",
       "      <td>0.541702</td>\n",
       "      <td>-0.053861</td>\n",
       "      <td>0.112671</td>\n",
       "      <td>-3.765371</td>\n",
       "      <td>-1.071238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        scaled_amount  scaled_time         V1        V2         V3         V4  \\\n",
       "707          0.041920    -0.988710  -1.393265 -1.095569   2.607795  -2.529060   \n",
       "254395      -0.201355     0.846086   0.202402  1.176270   0.346379   2.882138   \n",
       "218054       0.111786     0.663307  -2.034328 -1.285472   1.857375   0.800984   \n",
       "10801       -0.293440    -0.778827 -14.474437  6.503185 -17.712632  11.270352   \n",
       "44270       -0.293440    -0.503084 -20.906908  9.843153 -19.947726   6.155789   \n",
       "\n",
       "               V5        V6         V7        V8  ...       V20       V21  \\\n",
       "707     -0.135265 -0.373239   0.221446 -0.962847  ... -0.229820 -0.281365   \n",
       "254395   1.407133 -0.504355   1.438537 -0.395603  ... -0.206239  0.242560   \n",
       "218054   3.091875  1.584380  -0.289646  0.107165  ... -0.151415 -0.530614   \n",
       "10801   -4.150142 -3.372098 -16.535807 -1.443947  ...  1.101250 -2.475962   \n",
       "44270  -15.142013 -2.239566 -21.234463  1.151795  ...  0.396655 -1.977196   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "707     0.563218 -0.129765  0.089264  0.317551 -0.288551 -0.863521 -0.519168   \n",
       "254395  0.841230 -0.370157 -0.026012  0.491954  0.234576 -0.279788 -0.331933   \n",
       "218054 -0.810371 -0.377722 -1.004536  0.017659 -0.776990 -0.566835 -0.318421   \n",
       "10801   0.342391 -3.564508 -0.818140  0.153408  0.755079  2.706566 -0.992916   \n",
       "44270   0.652932 -0.519777  0.541702 -0.053861  0.112671 -3.765371 -1.071238   \n",
       "\n",
       "        Class  \n",
       "707         0  \n",
       "254395      1  \n",
       "218054      0  \n",
       "10801       1  \n",
       "44270       1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random under sampling - risk to non accurate performace due to trade and information loss\n",
    "# before 28314 now 492 of non fraud\n",
    "# removing data to have more balanced data and avoiding overfitting\n",
    "\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "fraud_data = data.loc[data['Class']==1]\n",
    "non_fraud_data = data.loc[data['Class']==0][:492]      # 492 are fraud cases 50 - 50 ration by 492\n",
    "\n",
    "normal_distributed_data = pd.concat([fraud_data, non_fraud_data]) # skewed to normal\n",
    "\n",
    "new_data = normal_distributed_data.sample(frac = 1, random_state = 42) # shuffle to retain accuracy \n",
    "\n",
    "new_data.head() # contain equal amount of both classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equally distributed classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of classses in subsample dataset\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: Class, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Distribution of classses in subsample dataset')\n",
    "print(new_data['Class'].value_counts() / len(new_data))\n",
    "\n",
    "sns.countplot('Class', data = new_data)\n",
    "plt.title('Equally Distributed Classes', fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_data.drop('Class', axis = 1)\n",
    "y = new_data['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array for all test and train values\n",
    "X_train.values\n",
    "X_test.values\n",
    "y_train.values\n",
    "y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary key = \"name of algorithm\", value = name of functions\n",
    "classifiers = { \n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"KNearest\": KNeighborsClassifier(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers:  LogisticRegression Has training score of 94.0\n",
      "Classifiers:  KNearest Has training score of 93.0\n",
      "Classifiers:  Support Vector Classifier Has training score of 92.0\n",
      "Classifiers:  DecisionTreeClassifier Has training score of 90.0\n"
     ]
    }
   ],
   "source": [
    "for key, classifier in classifiers.items():\n",
    "    classifier.fit(X_train, y_train)\n",
    "    training_score = cross_val_score(classifier, X_train, y_train, cv = 5)\n",
    "    print(\"Classifiers: \",  key, \"Has training score of\", round(training_score.mean(), 2) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LinearRegression cross validation score: 94.15%\n",
      "The KNN cross validation score: 92.88%\n",
      "The Support Vector Machine cross validation score: 92.37%\n",
      "The Tree cross validation score: 90.09%\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "SVM = SVC()\n",
    "Tree = DecisionTreeClassifier()\n",
    "\n",
    "algorithms = [LR, KNN, SVM, Tree]\n",
    "\n",
    "scores = ['LinearRegression', 'KNN', 'Support Vector Machine', 'Tree']\n",
    "\n",
    "#LR_score = cross_val_score(LR, X_train, y_train, cv=5)\n",
    "#print(\"The LR cross validation score: \", round(LR_score.mean(). * 100, 2).astype(str) + '%')\n",
    "\n",
    "for i in range(len(scores)):\n",
    "    sc = cross_val_score(algorithms[i], X_train, y_train, cv = 5)\n",
    "    print(\"The {0} cross validation score: {1}%\".format(scores[i], round(sc.mean() * 100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and AUC - performace measures for classification problems at various threshold settings\n",
    "# roc - probability curve, auc - degree or measure of separability\n",
    "# how much model is capable of distinguishing between two classes\n",
    "# high AUc = model is accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC curve predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "LR_pred = cross_val_predict(LR, X_train, y_train, cv=5, method=\"decision_function\")\n",
    "\n",
    "KNN_pred = cross_val_predict(KNN, X_train, y_train, cv=5)\n",
    "\n",
    "SVM_pred = cross_val_predict(LR, X_train, y_train, cv=5, method=\"decision_function\")\n",
    "\n",
    "Tree_pred = cross_val_predict(LR, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR ROC Score:  0.9768728588972917\n",
      "KNN ROC Score:  0.9278165600155129\n",
      "SVM ROC Score:  0.9768728588972917\n",
      "Tree ROC Score:  0.9407569000064636\n"
     ]
    }
   ],
   "source": [
    "print('LR ROC Score: ', roc_auc_score(y_train, LR_pred))\n",
    "print('KNN ROC Score: ', roc_auc_score(y_train, KNN_pred))\n",
    "print('SVM ROC Score: ', roc_auc_score(y_train, SVM_pred))\n",
    "print('Tree ROC Score: ', roc_auc_score(y_train, Tree_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Algorithm\n",
    "# Objective - to divide a hyper plane in n dimensional space, n = number of features in dataset and it classifies\n",
    "# the data points\n",
    "#Obj - to find hyperplane with maximum margine i.e maximum distance between both classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
